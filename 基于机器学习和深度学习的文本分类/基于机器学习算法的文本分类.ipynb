{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于机器学习算法的文本分类\n",
    "\n",
    "- TF-IDF\n",
    "- Count Features\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- SVM\n",
    "- Xgboost\n",
    "- Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>分类</th>\n",
       "      <th>正文</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>艺术</td>\n",
       "      <td>﻿【 文献号 】1-2432\\n【原文出处】出版发行研究\\n【原刊地名】京\\n【原刊期号】1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>艺术</td>\n",
       "      <td>﻿【 文献号 】1-2435\\n【原文出处】扬州师院学报：社科版\\n【原刊期号】199504...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>艺术</td>\n",
       "      <td>﻿【 文献号 】1-2785\\n【原文出处】南通师专学报：社科版\\n【原刊期号】199503...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>艺术</td>\n",
       "      <td>﻿【 文献号 】1-3021\\n【原文出处】社会科学战线\\n【原刊地名】长春\\n【原刊期号】...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>艺术</td>\n",
       "      <td>﻿【 文献号 】1-3062\\n【原文出处】上海文化\\n【原刊期号】199505\\n【原刊页...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   分类                                                 正文\n",
       "0  艺术  ﻿【 文献号 】1-2432\\n【原文出处】出版发行研究\\n【原刊地名】京\\n【原刊期号】1...\n",
       "1  艺术  ﻿【 文献号 】1-2435\\n【原文出处】扬州师院学报：社科版\\n【原刊期号】199504...\n",
       "2  艺术  ﻿【 文献号 】1-2785\\n【原文出处】南通师专学报：社科版\\n【原刊期号】199503...\n",
       "3  艺术  ﻿【 文献号 】1-3021\\n【原文出处】社会科学战线\\n【原刊地名】长春\\n【原刊期号】...\n",
       "4  艺术  ﻿【 文献号 】1-3062\\n【原文出处】上海文化\\n【原刊期号】199505\\n【原刊页..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"复旦大学中文文本分类语料.xlsx\",\"sheet1\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['艺术', '文学', '哲学', '通信', '能源', '历史', '矿藏', '空间', '教育', '交通', '计算机',\n",
       "       '环境', '电子', '农业', '体育', '时政', '医疗', '经济', '法律'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['分类'].unique() # 共19类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9249, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\蓝沛辉\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.660 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>分类</th>\n",
       "      <th>正文</th>\n",
       "      <th>文本分词</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>艺术</td>\n",
       "      <td>﻿【 文献号 】1-2432\\n【原文出处】出版发行研究\\n【原刊地名】京\\n【原刊期号】1...</td>\n",
       "      <td>﻿ 【   文献号   】 1 - 2432 \\n 【 原文 出处 】 出版发行 研究 \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>艺术</td>\n",
       "      <td>﻿【 文献号 】1-2435\\n【原文出处】扬州师院学报：社科版\\n【原刊期号】199504...</td>\n",
       "      <td>﻿ 【   文献号   】 1 - 2435 \\n 【 原文 出处 】 扬州 师院 学报 ：...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>艺术</td>\n",
       "      <td>﻿【 文献号 】1-2785\\n【原文出处】南通师专学报：社科版\\n【原刊期号】199503...</td>\n",
       "      <td>﻿ 【   文献号   】 1 - 2785 \\n 【 原文 出处 】 南通 师专 学报 ：...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>艺术</td>\n",
       "      <td>﻿【 文献号 】1-3021\\n【原文出处】社会科学战线\\n【原刊地名】长春\\n【原刊期号】...</td>\n",
       "      <td>﻿ 【   文献号   】 1 - 3021 \\n 【 原文 出处 】 社会科学 战线 \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>艺术</td>\n",
       "      <td>﻿【 文献号 】1-3062\\n【原文出处】上海文化\\n【原刊期号】199505\\n【原刊页...</td>\n",
       "      <td>﻿ 【   文献号   】 1 - 3062 \\n 【 原文 出处 】 上海 文化 \\n 【...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   分类                                                 正文  \\\n",
       "0  艺术  ﻿【 文献号 】1-2432\\n【原文出处】出版发行研究\\n【原刊地名】京\\n【原刊期号】1...   \n",
       "1  艺术  ﻿【 文献号 】1-2435\\n【原文出处】扬州师院学报：社科版\\n【原刊期号】199504...   \n",
       "2  艺术  ﻿【 文献号 】1-2785\\n【原文出处】南通师专学报：社科版\\n【原刊期号】199503...   \n",
       "3  艺术  ﻿【 文献号 】1-3021\\n【原文出处】社会科学战线\\n【原刊地名】长春\\n【原刊期号】...   \n",
       "4  艺术  ﻿【 文献号 】1-3062\\n【原文出处】上海文化\\n【原刊期号】199505\\n【原刊页...   \n",
       "\n",
       "                                                文本分词  \n",
       "0  ﻿ 【   文献号   】 1 - 2432 \\n 【 原文 出处 】 出版发行 研究 \\n...  \n",
       "1  ﻿ 【   文献号   】 1 - 2435 \\n 【 原文 出处 】 扬州 师院 学报 ：...  \n",
       "2  ﻿ 【   文献号   】 1 - 2785 \\n 【 原文 出处 】 南通 师专 学报 ：...  \n",
       "3  ﻿ 【   文献号   】 1 - 3021 \\n 【 原文 出处 】 社会科学 战线 \\n...  \n",
       "4  ﻿ 【   文献号   】 1 - 3062 \\n 【 原文 出处 】 上海 文化 \\n 【...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "data['文本分词'] = data['正文'].apply(lambda x:jieba.cut(x)) # 生成器形式\n",
    "data['文本分词'] = [' '.join(i) for i in data['文本分词']] # 空格拼接\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存本地\n",
    "data[['分类','文本分词']].to_csv(\"data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编码类别标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "encode = preprocessing.LabelEncoder()\n",
    "label =  encode.fit_transform(data['分类'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 16, 16, 16, 16, 16, 16, 16, 16, 16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8324,)\n",
      "(925,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_valid,Y_train,Y_valid = train_test_split(data['文本分词'].values, label,stratify=label, random_state=42, test_size=0.1,shuffle=True ) \n",
    "# stratify=y : 按照数据集中y的比例分配给train和test，使得train和test中各类别数据的比例与原数据集的比例一致。\n",
    "print (X_train.shape)\n",
    "print (X_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本向量化\n",
    "\n",
    "- TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_encode(tokens):\n",
    "    \"\"\"将数字映射为同一个符号：#NUMBER\"\"\"\n",
    "    return (\"#NUMBER\" if tokens[0].isdigit() else token for token in tokens)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "class Vectorizer(TfidfVectorizer):\n",
    "    def build_tokenizer(self):\n",
    "        tokenize = super(Vectorizer, self).build_tokenizer()\n",
    "        return lambda doc:list(number_encode(tokenize(doc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [line.strip() for line in open('中文停用词表.txt', 'r', encoding='utf-8').readlines()] # 停用词表\n",
    "\n",
    "tf_idf = Vectorizer(min_df=3,max_df=0.5,max_features=None,ngram_range=(1,2),use_idf=True,smooth_idf=True,stop_words=stop_words)\n",
    "\n",
    "# min_df 构建词汇表时忽略文档频率低于该值的词(整数为绝对值，浮点数为比例，默认1)\n",
    "# max_df 构建词汇表时忽略文档频率高于该值的词(整数为绝对值，浮点数为比例，默认1)\n",
    "# max_feature 构建词汇表时仅考虑按语料词频排序的前N个\n",
    "# ngram_range 要提取的ngram特征的上下限\n",
    "# user_idf 启动idf重新计算权重\n",
    "# smooth_idf 对文档频率加1以平滑权重，防止除零\n",
    "# stop_words 停用词表，用于剔除停用词，若为english，启用内建词表\n",
    "\n",
    "# 词袋模型\n",
    "# count_vec = CountVectorizer(min_df=3,max_df=0.5, ngram_range=(1,2),stop_words = stwlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8324, 932205)\n",
      "(925, 932205)\n"
     ]
    }
   ],
   "source": [
    "tf_idf.fit(list(X_train) + list(X_valid))\n",
    "X_train_vec = tf_idf.transform(X_train)\n",
    "X_valid_vec = tf_idf.transform(X_valid)\n",
    "print (X_train_vec.shape)\n",
    "print (X_valid_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多分类交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"\n",
    "     对数损失度量的多分类版本。\n",
    "    :param actual: 包含actual target classes的数组\n",
    "    :param predicted: 分类预测结果矩阵, 每个类别都有一个概率\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1])) # 将真实标签转化为矩阵[0,0,1,0,0]\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps) # eps最小，1-eps最大，避免求对数出现问题\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip)) # 两个矩阵各元素乘机之和\n",
    "    return -1.0 / rows * vsota # 负的交叉熵之和除以样本数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逻辑回归分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software_install_here\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多分类交叉熵损失：0.607\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=1.0, solver='lbfgs', multi_class='multinomial') # 参数 https://blog.csdn.net/qq_27972567/article/details/81949023\n",
    "lr.fit(X_train_vec,Y_train)\n",
    "pred = lr.predict_proba(X_valid_vec)\n",
    "print(\"多分类交叉熵损失：%0.3f\" % multiclass_logloss(Y_valid,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 朴素贝叶斯分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多分类交叉熵损失：0.968\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vec,Y_train)\n",
    "pred = nb.predict_proba(X_valid_vec)\n",
    "print(\"多分类交叉熵损失：%0.3f\" % multiclass_logloss(Y_valid,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, decomposition\n",
    "\n",
    "svd = decomposition.TruncatedSVD(n_components=120)\n",
    "svd.fit(X_train_vec)\n",
    "\n",
    "X_train_svd = svd.transform(X_train_vec)\n",
    "X_valid_svd = svd.transform(X_valid_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8324, 120)\n",
      "(925, 120)\n"
     ]
    }
   ],
   "source": [
    "print (X_train_svd.shape)\n",
    "print (X_valid_svd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = preprocessing.StandardScaler()\n",
    "scale.fit(X_train_svd)\n",
    "\n",
    "X_train_svd_st = scale.transform(X_train_svd)\n",
    "X_valid_svd_st = scale.transform(X_valid_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多分类交叉熵损失：0.356\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(C=1.0, probability=True)\n",
    "svc.fit(X_train_svd_st, Y_train)\n",
    "pred = svc.predict_proba(X_valid_svd_st)\n",
    "\n",
    "print(\"多分类交叉熵损失：%0.3f\" % multiclass_logloss(Y_valid,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多分类交叉熵损失：0.371\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "boost = xgb.XGBClassifier(max_depth=7, n_estimator=200,colsample_bytree=0.8,subsample=0.8, nthread=10,learning_rate=0.1)\n",
    "boost.fit(X_train_svd,Y_train)\n",
    "pred = boost.predict_proba(X_valid_svd)\n",
    "print(\"多分类交叉熵损失：%0.3f\" % multiclass_logloss(Y_valid,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网格搜索参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics, pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "scorer = metrics.make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True) # 构建评分函数\n",
    "\n",
    "# 构建pipeline\n",
    "svd = decomposition.TruncatedSVD()\n",
    "scale = preprocessing.StandardScaler()\n",
    "lr = LogisticRegression()\n",
    "\n",
    "pipelines = pipeline.Pipeline([('svd',svd),\n",
    "                          ('scale',scale),\n",
    "                          ('lr',lr)])\n",
    "\n",
    "# 参数字典\n",
    "params = {'svd__n_components':[120,180],\n",
    "         'lr__C':[0.1,1.0,10],\n",
    "         'lr__penalty':['l1','l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed: 21.5min\n",
      "D:\\Software_install_here\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 23.4min\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  24 | elapsed: 23.8min remaining: 23.8min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  24 | elapsed: 24.4min remaining: 14.6min\n"
     ]
    }
   ],
   "source": [
    "model = GridSearchCV(estimator=pipelines, param_grid=params,scoring=scorer,verbose=10,n_jobs=-1,iid=True,refit=True,cv=2)\n",
    "model.fit(X_train_vec,Y_train)\n",
    "print(\"最佳分数：%0.3f\" % model.best_score_)\n",
    "print(\"最佳参数集：\")\n",
    "best_params = model.best_estimator_.get_params()\n",
    "for param in sorted(params.keys()):\n",
    "    print(\"\\t%s: %r\" % (param, best_params[param]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
